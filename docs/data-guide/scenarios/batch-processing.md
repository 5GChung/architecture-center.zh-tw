---
title: "批次處理"
description: 
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: 55113b61c2684a7826fa6c0034503f842cdb840f
ms.sourcegitcommit: 90cf2de795e50571d597cfcb9b302e48933e7f18
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 02/14/2018
---
# <a name="batch-processing"></a><span data-ttu-id="b683f-102">批次處理</span><span class="sxs-lookup"><span data-stu-id="b683f-102">Batch processing</span></span>

<span data-ttu-id="b683f-103">待用資料的批次處理是常見的巨量資料案例。</span><span class="sxs-lookup"><span data-stu-id="b683f-103">A common big data scenario is batch processing of data at rest.</span></span> <span data-ttu-id="b683f-104">在此案例中，來源資料會經由來源應用程式本身或協調工作流程載入資料儲存體中。</span><span class="sxs-lookup"><span data-stu-id="b683f-104">In this scenario, the source data is loaded into data storage, either by the source application itself or by an orchestration workflow.</span></span> <span data-ttu-id="b683f-105">接著，資料會在平行化作業中就地處理，而此作業也可由協調工作流程起始。</span><span class="sxs-lookup"><span data-stu-id="b683f-105">The data is then processed in-place by a parallelized job, which can also be initiated by the orchestration workflow.</span></span> <span data-ttu-id="b683f-106">此處理在轉換的結果載入至分析資料存放區之前可能會包含多個反覆執行的步驟，而結果在載入後將可由分析和報告元件進行查詢。</span><span class="sxs-lookup"><span data-stu-id="b683f-106">The processing may include multiple iterative steps before the transformed results are loaded into an analytical data store, which can be queried by analytics and reporting components.</span></span>

<span data-ttu-id="b683f-107">例如，Web 伺服器的記錄可能會複製到資料夾，然後在經過一個晚上的處理後產生 Web 活動的每日報表。</span><span class="sxs-lookup"><span data-stu-id="b683f-107">For example, the logs from a web server might be copied to a folder and then processed overnight to generate daily reports of web activity.</span></span>

![](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a><span data-ttu-id="b683f-108">使用此解決方案的時機</span><span class="sxs-lookup"><span data-stu-id="b683f-108">When to use this solution</span></span>

<span data-ttu-id="b683f-109">在許多情況下都會使用批次處理，從簡單的資料轉換，到更完整的 ETL (擷取-轉換-載入) 管線，都會用到。</span><span class="sxs-lookup"><span data-stu-id="b683f-109">Batch processing is used in a variety of scenarios, from simple data transformations to a more complete ETL (extract-transform-load) pipeline.</span></span> <span data-ttu-id="b683f-110">在巨量資料內容中，批次處理可能會運用在非常大型的資料集上，而其計算會非常耗時。</span><span class="sxs-lookup"><span data-stu-id="b683f-110">In a big data context, batch processing may operate over very large data sets, where the computation takes significant time.</span></span> <span data-ttu-id="b683f-111">(如需範例，請參閱 [Lambda 架構](../concepts/big-data.md##lambda-architecture)。)批次處理通常會帶來進一步的互動式瀏覽、提供可用來建立模型的資料供機器學習使用，或將資料寫入至最適合用於分析和視覺效果的資料存放區。</span><span class="sxs-lookup"><span data-stu-id="b683f-111">(For example, see [Lambda architecture](../concepts/big-data.md##lambda-architecture).) Batch processing typically leads to further interactive exploration, provides the modeling-ready data for machine learning, or writes the data to a data store that is optimized for analytics and visualization.</span></span>

<span data-ttu-id="b683f-112">批次處理的範例之一，是將半結構化的一般 CSV 或 JSON 大型檔案集轉換為可供進一步查詢的結構描述化和結構化格式。</span><span class="sxs-lookup"><span data-stu-id="b683f-112">One example of batch processing is transforming a large set of flat, semi-structured CSV or JSON files into a schematized and structured format that is ready for further querying.</span></span> <span data-ttu-id="b683f-113">一般而言，資料會從用於擷取的原始格式 (例如 CSV) 轉換為可提升查詢效能的二進位格式，因為它們會以單欄格式儲存資料，且通常會提供資料的關於索引和統計資料。</span><span class="sxs-lookup"><span data-stu-id="b683f-113">Typically the data is converted from the raw formats used for ingestion (such as CSV) into binary formats that are more performant for querying because they store data in a columnar format, and often provide indexes and inline statistics about the data.</span></span>

## <a name="challenges"></a><span data-ttu-id="b683f-114">挑戰</span><span class="sxs-lookup"><span data-stu-id="b683f-114">Challenges</span></span>

- <span data-ttu-id="b683f-115">**資料格式和編碼**。</span><span class="sxs-lookup"><span data-stu-id="b683f-115">**Data format and encoding**.</span></span> <span data-ttu-id="b683f-116">有些最難以偵錯的問題，常發生在檔案使用未預期的格式或編碼時。</span><span class="sxs-lookup"><span data-stu-id="b683f-116">Some of the most difficult issues to debug happen when files use an unexpected format or encoding.</span></span> <span data-ttu-id="b683f-117">例如，來源檔案可能混用 UTF-16 和 UTF-8 編碼，或包含未預期的分隔符號 (空格與定位點)，或是包含未預期的字元。</span><span class="sxs-lookup"><span data-stu-id="b683f-117">For example, source files might use a mix of UTF-16 and UTF-8 encoding, or contain unexpected delimiters (space versus tab), or include unexpected characters.</span></span> <span data-ttu-id="b683f-118">另一個常見範例，是文字欄位中包含會解譯為分隔符號的定位點、空格或逗點。</span><span class="sxs-lookup"><span data-stu-id="b683f-118">Another common example is text fields that contain tabs, spaces, or commas that are interpreted as delimiters.</span></span> <span data-ttu-id="b683f-119">資料載入和剖析邏輯必須有足夠的彈性來偵測及處理這些問題。</span><span class="sxs-lookup"><span data-stu-id="b683f-119">Data loading and parsing logic must be flexible enough to detect and handle these issues.</span></span>

- <span data-ttu-id="b683f-120">**協調時間配量。**</span><span class="sxs-lookup"><span data-stu-id="b683f-120">**Orchestrating time slices.**</span></span> <span data-ttu-id="b683f-121">來源資料常會放在可反映處理時間範圍，並依年、月、日、小時等單位組織的資料夾階層中。</span><span class="sxs-lookup"><span data-stu-id="b683f-121">Often source data is placed in a folder hierarchy that reflects processing windows, organized by year, month, day, hour, and so on.</span></span> <span data-ttu-id="b683f-122">在某些情況下，資料可能會延遲送達。</span><span class="sxs-lookup"><span data-stu-id="b683f-122">In some cases, data may arrive late.</span></span> <span data-ttu-id="b683f-123">例如，假設 Web 伺服器失敗，而且 3 月 7 日的記錄直到 3 月 9 日才送達資料夾以進行處理。</span><span class="sxs-lookup"><span data-stu-id="b683f-123">For example, suppose that a web server fails, and the logs for March 7th don't end up in the folder for processing until March 9th.</span></span> <span data-ttu-id="b683f-124">這些記錄會因為太晚送達而遭到忽略嗎？</span><span class="sxs-lookup"><span data-stu-id="b683f-124">Are they just ignored because they're too late?</span></span> <span data-ttu-id="b683f-125">下游處理邏輯可處理順序錯亂的記錄嗎？</span><span class="sxs-lookup"><span data-stu-id="b683f-125">Can the downstream processing logic handle out-of-order records?</span></span>

## <a name="architecture"></a><span data-ttu-id="b683f-126">架構</span><span class="sxs-lookup"><span data-stu-id="b683f-126">Architecture</span></span>

<span data-ttu-id="b683f-127">批次處理架構具有下列邏輯元件，如下圖所示。</span><span class="sxs-lookup"><span data-stu-id="b683f-127">A batch processing architecture has the following logical components, shown in the diagram above.</span></span>

- <span data-ttu-id="b683f-128">**資料儲存體**。</span><span class="sxs-lookup"><span data-stu-id="b683f-128">**Data storage.**</span></span> <span data-ttu-id="b683f-129">通常是可作為儲存庫的分散式檔案存放區，用以保存大量具有不同格式的大型檔案。</span><span class="sxs-lookup"><span data-stu-id="b683f-129">Typically a distributed file store that can serve as a repository for high volumes of large files in various formats.</span></span> <span data-ttu-id="b683f-130">一般而言，這種存放區通常稱為 Data Lake。</span><span class="sxs-lookup"><span data-stu-id="b683f-130">Generically, this kind of store is often referred to as a data lake.</span></span> 

- <span data-ttu-id="b683f-131">**批次處理。**</span><span class="sxs-lookup"><span data-stu-id="b683f-131">**Batch processing.**</span></span> <span data-ttu-id="b683f-132">巨量資料具有大量的特性，這常意味著解決方案通常必須使用需要長時間執行的批次作業來處理資料檔案，以便篩選、彙總和準備資料以供分析。</span><span class="sxs-lookup"><span data-stu-id="b683f-132">The high-volume nature of big data often means that solutions must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="b683f-133">這些作業通常涉及讀取原始程式檔、加以處理，然後將輸出寫入至新的檔案。</span><span class="sxs-lookup"><span data-stu-id="b683f-133">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> 

- <span data-ttu-id="b683f-134">**分析資料存放區。**</span><span class="sxs-lookup"><span data-stu-id="b683f-134">**Analytical data store.**</span></span> <span data-ttu-id="b683f-135">許多巨量資料解決方案會準備資料以供分析，然後以可使用分析工具來查詢的結構化格式提供處理過的資料。</span><span class="sxs-lookup"><span data-stu-id="b683f-135">Many big data solutions are designed to prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> 

- <span data-ttu-id="b683f-136">**分析和報告。**</span><span class="sxs-lookup"><span data-stu-id="b683f-136">**Analysis and reporting.**</span></span> <span data-ttu-id="b683f-137">大部分巨量資料解決方案的目標，是要透過分析和報告提供深入判讀資料的能力。</span><span class="sxs-lookup"><span data-stu-id="b683f-137">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> 

- <span data-ttu-id="b683f-138">**協調流程**。</span><span class="sxs-lookup"><span data-stu-id="b683f-138">**Orchestration.**</span></span> <span data-ttu-id="b683f-139">使用批次處理時，通常需要某些協調流程，以將資料移轉或複製到您的資料儲存體、批次處理、分析資料存放區和報告層中。</span><span class="sxs-lookup"><span data-stu-id="b683f-139">With batch processing, typically some orchestration is required to migrate or copy the data into your data storage, batch processing, analytical data store, and reporting layers.</span></span>

## <a name="technology-choices"></a><span data-ttu-id="b683f-140">技術選擇</span><span class="sxs-lookup"><span data-stu-id="b683f-140">Technology choices</span></span>

<span data-ttu-id="b683f-141">下列技術是 Azure 中的批次處理解決方案適用的建議選項。</span><span class="sxs-lookup"><span data-stu-id="b683f-141">The following technologies are recommended choices for batch processing solutions in Azure.</span></span>

### <a name="data-storage"></a><span data-ttu-id="b683f-142">資料儲存體</span><span class="sxs-lookup"><span data-stu-id="b683f-142">Data storage</span></span>

- <span data-ttu-id="b683f-143">**Azure 儲存體 Blob 容器**。</span><span class="sxs-lookup"><span data-stu-id="b683f-143">**Azure Storage Blob Containers**.</span></span> <span data-ttu-id="b683f-144">許多現有的 Azure 商業程序已開始使用 Azure Blob 儲存體，因此這已成為巨量資料存放區的理想選擇。</span><span class="sxs-lookup"><span data-stu-id="b683f-144">Many existing Azure business processes already make use of Azure blob storage, making this a good choice for a big data store.</span></span>
- <span data-ttu-id="b683f-145">**Azure Data Lake Store**。</span><span class="sxs-lookup"><span data-stu-id="b683f-145">**Azure Data Lake Store**.</span></span> <span data-ttu-id="b683f-146">Azure Data Lake Store 提供幾乎不受限制、任何大小的檔案皆適用的儲存體，並提供多方面的安全性選項，因此對於需要以集中式存放區處理異質資料格式的超大型巨量資料解決方案而言，可說是絕佳選擇。</span><span class="sxs-lookup"><span data-stu-id="b683f-146">Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.</span></span>

<span data-ttu-id="b683f-147">如需詳細資訊，請參閱[資料儲存體](../technology-choices/data-storage.md)。</span><span class="sxs-lookup"><span data-stu-id="b683f-147">For more information, see [Data storage](../technology-choices/data-storage.md).</span></span>

### <a name="batch-processing"></a><span data-ttu-id="b683f-148">批次處理</span><span class="sxs-lookup"><span data-stu-id="b683f-148">Batch processing</span></span>

- <span data-ttu-id="b683f-149">**U-SQL**。</span><span class="sxs-lookup"><span data-stu-id="b683f-149">**U-SQL**.</span></span> <span data-ttu-id="b683f-150">U-SQL 是 Azure Data Lake Analytics 所使用的查詢處理語言。</span><span class="sxs-lookup"><span data-stu-id="b683f-150">U-SQL is the query processing language used by Azure Data Lake Analytics.</span></span> <span data-ttu-id="b683f-151">它結合了 SQL 的宣告式特性與 C# 的程序擴充功能，並利用平行處理能力來支援大規模資料的有效處理。</span><span class="sxs-lookup"><span data-stu-id="b683f-151">It combines the declarative nature of SQL with the procedural extensibility of C#, and takes advantage of parallelism to enable efficient processing of data at massive scale.</span></span>
- <span data-ttu-id="b683f-152">**Hive**。</span><span class="sxs-lookup"><span data-stu-id="b683f-152">**Hive**.</span></span> <span data-ttu-id="b683f-153">Hive 是一種類似於 SQL 的語言，在大部分的 Hadoop 發行版中均受支援，包括 HDInsight。</span><span class="sxs-lookup"><span data-stu-id="b683f-153">Hive is a SQL-like language that is supported in most Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="b683f-154">它可用來處理來自任何 HDFS 相容存放區的資料，包括 Azure Blob 儲存體和 Azure Data Lake Store。</span><span class="sxs-lookup"><span data-stu-id="b683f-154">It can be used to process data from any HDFS-compatible store, including Azure blob storage and Azure Data Lake Store.</span></span>
- <span data-ttu-id="b683f-155">**Pig**。</span><span class="sxs-lookup"><span data-stu-id="b683f-155">**Pig**.</span></span> <span data-ttu-id="b683f-156">Pig 是許多 Hadoop 發行版 (包括 HDInsight) 中使用的宣告式巨量資料處理語言。</span><span class="sxs-lookup"><span data-stu-id="b683f-156">Pig is a declarative big data processing language used in many Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="b683f-157">它特別適合用來處理非結構化或半結構化資料。</span><span class="sxs-lookup"><span data-stu-id="b683f-157">It is particularly useful for processing data that is unstructured or semi-structured.</span></span>
- <span data-ttu-id="b683f-158">**Spark**。</span><span class="sxs-lookup"><span data-stu-id="b683f-158">**Spark**.</span></span> <span data-ttu-id="b683f-159">Spark 引擎支援以多種語言撰寫的批次處理程式，包括 Java、Scala 和 Python。</span><span class="sxs-lookup"><span data-stu-id="b683f-159">The Spark engine supports batch processing programs written in a range of languages, including Java, Scala, and Python.</span></span> <span data-ttu-id="b683f-160">Spark 可使用分散式架構以平行方式處理多個背景工作節點間的資料。</span><span class="sxs-lookup"><span data-stu-id="b683f-160">Spark uses a distributed architecture to process data in parallel across multiple worker nodes.</span></span>

<span data-ttu-id="b683f-161">如需詳細資訊，請參閱[批次處理](../technology-choices/batch-processing.md)。</span><span class="sxs-lookup"><span data-stu-id="b683f-161">For more information, see [Batch processing](../technology-choices/batch-processing.md).</span></span>

### <a name="analytical-data-store"></a><span data-ttu-id="b683f-162">分析資料存放區</span><span class="sxs-lookup"><span data-stu-id="b683f-162">Analytical data store</span></span>

- <span data-ttu-id="b683f-163">**SQL 資料倉儲**。</span><span class="sxs-lookup"><span data-stu-id="b683f-163">**SQL Data Warehouse**.</span></span> <span data-ttu-id="b683f-164">Azure SQL 資料倉儲是以 SQL Server 資料庫技術為基礎的受控服務，並經過最佳化而可支援大規模的資料倉儲工作負載。</span><span class="sxs-lookup"><span data-stu-id="b683f-164">Azure SQL Data Warehouse is a managed service based on SQL Server database technologies and optimized to support large-scale data warehousing workloads.</span></span>
- <span data-ttu-id="b683f-165">**Spark SQL**。</span><span class="sxs-lookup"><span data-stu-id="b683f-165">**Spark SQL**.</span></span> <span data-ttu-id="b683f-166">Spark SQL 是以 Spark 作為建置基礎的 API，可支援您建立能夠使用 SQL 語法來查詢的資料框架和資料表。</span><span class="sxs-lookup"><span data-stu-id="b683f-166">Spark SQL is an API built on Spark that supports the creation of dataframes and tables that can be queried using SQL syntax.</span></span>
- <span data-ttu-id="b683f-167">**HBase**。</span><span class="sxs-lookup"><span data-stu-id="b683f-167">**HBase**.</span></span> <span data-ttu-id="b683f-168">對 HBase 是一種低延遲的 NoSQL 存放區，可提供高效能、有彈性的選項，用以查詢結構化和半結構化資料。</span><span class="sxs-lookup"><span data-stu-id="b683f-168">HBase is a low-latency NoSQL store that offers a high-performance, flexible option for querying structured and semi-structured data.</span></span>
- <span data-ttu-id="b683f-169">**Hive**。</span><span class="sxs-lookup"><span data-stu-id="b683f-169">**Hive**.</span></span> <span data-ttu-id="b683f-170">除了適用於批次處理，Hive 也提供在概念上類似於一般關聯式資料庫管理系統的資料庫結構。</span><span class="sxs-lookup"><span data-stu-id="b683f-170">In addition to being useful for batch processing, Hive offers a database architecture that is conceptually similar to that of a typical relational database management system.</span></span> <span data-ttu-id="b683f-171">Hive 查詢經由 Tez 引擎和 Stinger Initiative 之類的創新而產生了效能上的提升，這意味著 Hive 資料表在某些情況下可有效作為分析查詢的來源。</span><span class="sxs-lookup"><span data-stu-id="b683f-171">Improvements in Hive query performance through innovations like the Tez engine and Stinger initiative mean that Hive tables can be used effectively as sources for analytical queries in some scenarios.</span></span>

<span data-ttu-id="b683f-172">如需詳細資訊，請參閱[分析資料存放區](../technology-choices/analytical-data-stores.md)。</span><span class="sxs-lookup"><span data-stu-id="b683f-172">For more information, see [Analytical data stores](../technology-choices/analytical-data-stores.md).</span></span>

### <a name="analytics-and-reporting"></a><span data-ttu-id="b683f-173">分析和報告</span><span class="sxs-lookup"><span data-stu-id="b683f-173">Analytics and reporting</span></span>

- <span data-ttu-id="b683f-174">**Azure Analysis Services**。</span><span class="sxs-lookup"><span data-stu-id="b683f-174">**Azure Analysis Services**.</span></span> <span data-ttu-id="b683f-175">許多巨量資料解決方案皆模擬傳統企業商業智慧架構，而納入了可供報表、儀表板和互動式「切割與細分」分析作為基礎的集中式線上分析處理 (OLAP) 資料模型 (通常稱為 Cube)。</span><span class="sxs-lookup"><span data-stu-id="b683f-175">Many big data solutions emulate traditional enterprise business intelligence architectures by including a centralized online analytical processing (OLAP) data model (often referred to as a cube) on which reports, dashboards, and interactive “slice and dice” analysis can be based.</span></span> <span data-ttu-id="b683f-176">Azure Analysis Services 可支援您建立多維度和表格式模型，以符合此需求。</span><span class="sxs-lookup"><span data-stu-id="b683f-176">Azure Analysis Services supports the creation of multidimensional and tabular models to meet this need.</span></span>
- <span data-ttu-id="b683f-177">**Power BI**。</span><span class="sxs-lookup"><span data-stu-id="b683f-177">**Power BI**.</span></span> <span data-ttu-id="b683f-178">Power BI 可讓資料分析師根據 OLAP 模型中的資料模型建立互動式資料視覺效果，或直接從分析資料存放區建立。</span><span class="sxs-lookup"><span data-stu-id="b683f-178">Power BI enables data analysts to create interactive data visualizations based on data models in an OLAP model or directly from an analytical data store.</span></span>
- <span data-ttu-id="b683f-179">**Microsoft Excel**。</span><span class="sxs-lookup"><span data-stu-id="b683f-179">**Microsoft Excel**.</span></span> <span data-ttu-id="b683f-180">Microsoft Excel 是全世界最廣受使用的軟體應用程式之一，可提供豐富的資料分析和視覺效果功能。</span><span class="sxs-lookup"><span data-stu-id="b683f-180">Microsoft Excel is one of the most widely used software applications in the world, and offers a wealth of data analysis and visualization capabilities.</span></span> <span data-ttu-id="b683f-181">資料分析師可使用 Excel 從分析資料存放區建置文件資料模型，或將 OLAP 資料模型中的資料擷取到互動式樞紐分析表和圖表中。</span><span class="sxs-lookup"><span data-stu-id="b683f-181">Data analysts can use Excel to build document data models from analytical data stores, or to retrieve data from OLAP data models into interactive PivotTables and charts.</span></span>

<span data-ttu-id="b683f-182">如需詳細資訊，請參閱[分析和報告](../technology-choices/analysis-visualizations-reporting.md)。</span><span class="sxs-lookup"><span data-stu-id="b683f-182">For more information, see [Analytics and reporting](../technology-choices/analysis-visualizations-reporting.md).</span></span>

### <a name="orchestration"></a><span data-ttu-id="b683f-183">協調流程</span><span class="sxs-lookup"><span data-stu-id="b683f-183">Orchestration</span></span>

- <span data-ttu-id="b683f-184">**Azure Data Factory**。</span><span class="sxs-lookup"><span data-stu-id="b683f-184">**Azure Data Factory**.</span></span> <span data-ttu-id="b683f-185">Azure Data Factory 管線可用來定義一系列排程於週期性時間範圍的活動。</span><span class="sxs-lookup"><span data-stu-id="b683f-185">Azure Data Factory pipelines can be used to define a sequence of activities, scheduled for recurring temporal windows.</span></span> <span data-ttu-id="b683f-186">這些活動可起始資料複製作業以及隨需 HDInsight 叢集中的 Hive、Pig、MapReduce 或 Spark 作業；Azure Date Lake Analytics 中的 U-SQL 作業，和 Azure SQL 資料倉儲或 Azure SQL Database 中的預存程序。</span><span class="sxs-lookup"><span data-stu-id="b683f-186">These activities can initiate data copy operations as well as Hive, Pig, MapReduce, or Spark jobs in on-demand HDInsight clusters; U-SQL jobs in Azure Date Lake Analytics; and stored procedures in Azure SQL Data Warehouse or Azure SQL Database.</span></span>
- <span data-ttu-id="b683f-187">**Oozie** 和 **Sqoop**。</span><span class="sxs-lookup"><span data-stu-id="b683f-187">**Oozie** and **Sqoop**.</span></span> <span data-ttu-id="b683f-188">Oozie 是 Apache Hadoop 生態系統的作業自動化引擎，可用來起始資料複製作業以及處理資料的 Hive、Pig 和 MapReduce 作業，和在 HDFS 與 SQL 資料庫之間複製資料的 Sqoop 作業。</span><span class="sxs-lookup"><span data-stu-id="b683f-188">Oozie is a job automation engine for the Apache Hadoop ecosystem and can be used to initiate data copy operations as well as Hive, Pig, and MapReduce jobs to process data and Sqoop jobs to copy data between HDFS and SQL databases.</span></span>

<span data-ttu-id="b683f-189">如需詳細資訊，請參閱[管線協調流程](../technology-choices/pipeline-orchestration-data-movement.md)</span><span class="sxs-lookup"><span data-stu-id="b683f-189">For more information, see [Pipeline orchestration](../technology-choices/pipeline-orchestration-data-movement.md)</span></span>
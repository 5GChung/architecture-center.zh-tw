---
title: "微服務的資料考量"
description: "微服務的資料考量"
author: MikeWasson
ms.date: 12/08/2017
ms.openlocfilehash: 9bd7a8424309b5753b42cfb70559836288a3ce9d
ms.sourcegitcommit: c7f46b14ad7d55cf553b2d0b01045c9c25aefcdb
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 12/09/2017
---
# <a name="designing-microservices-data-considerations"></a><span data-ttu-id="2b6b6-103">設計微服務：資料考量</span><span class="sxs-lookup"><span data-stu-id="2b6b6-103">Designing microservices: Data considerations</span></span>

<span data-ttu-id="2b6b6-104">本章說明在微服務架構中管理資料時的考量。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-104">This chapter describes considerations for managing data in a microservices architecture.</span></span> <span data-ttu-id="2b6b6-105">因為每個微服務都會管理自己的資料，因此非常難以維持資料完整性和資料一致性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-105">Because every microservice manages its own data, data integrity and data consistency are critical challenges.</span></span>

![](./images/data-considerations.png)

<span data-ttu-id="2b6b6-106">微服務的基本原則是每個服務要管理自己的資料。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-106">A basic principle of microservices is that each service manages its own data.</span></span> <span data-ttu-id="2b6b6-107">兩項服務不應共用一個資料存放區。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-107">Two services should not share a data store.</span></span> <span data-ttu-id="2b6b6-108">相反地，每項服務都要負責自己的私用資料存放區，不可由其他服務直接存取。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-108">Instead, each service is responsible for its own private data store, which other services cannot access directly.</span></span>

<span data-ttu-id="2b6b6-109">之所以有此規則，是為了避免服務彼此意外結合，如果服務共用相同的基礎資料結構描述，就會導致這種情況發生。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-109">The reason for this rule is to avoid unintentional coupling between services, which can result if services share the same underlying data schemas.</span></span> <span data-ttu-id="2b6b6-110">如果資料結構描述有變更，則必須在依賴該資料庫的每個服務之間協調該項變更。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-110">If there is a change to the data schema, the change must be coordinated across every service that relies on that database.</span></span> <span data-ttu-id="2b6b6-111">藉由隔離每個服務的資料存放區，我們可以限制變更的範圍，並保留真正獨立部署的靈活度。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-111">By isolating each service's data store, we can limit the scope of change, and preserve the agility of truly independent deployments.</span></span> <span data-ttu-id="2b6b6-112">另一個原因是，每個微服務都可能會有自己的資料模型、查詢、或讀取/寫入模式。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-112">Another reason is that each microservice may have its own data models, queries, or read/write patterns.</span></span> <span data-ttu-id="2b6b6-113">使用共用的資料存放區會讓每個小組受到限制，而無法針對其特定的服務將資料儲存體最佳化。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-113">Using a shared data store limits each team's ability to optimize data storage for their particular service.</span></span> 

![](../guide/architecture-styles/images/cqrs-microservices-wrong.png)

<span data-ttu-id="2b6b6-114">這種方法會自然帶來[多語言持續性](https://martinfowler.com/bliki/PolyglotPersistence.html)，亦即在單一應用程式中使用多個資料儲存體技術的特性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-114">This approach naturally leads to [polyglot persistence](https://martinfowler.com/bliki/PolyglotPersistence.html) &mdash; the use of multiple data storage technologies within a single application.</span></span> <span data-ttu-id="2b6b6-115">某項服務可能需要文件資料庫的「讀取時建立結構描述 (schema-on-read)」功能。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-115">One service might require the schema-on-read capabilities of a document database.</span></span> <span data-ttu-id="2b6b6-116">另一項服務則可能需要 RDBMS 所提供的參考完整性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-116">Another might need the referential integrity provided by an RDBMS.</span></span> <span data-ttu-id="2b6b6-117">每個小組可自由選擇最適合其服務使用的語言。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-117">Each team is free to make the best choice for their service.</span></span> <span data-ttu-id="2b6b6-118">如需多語言持續性一般原則的詳細資訊，請參閱[使用作業的最佳資料存放區](../guide/design-principles/use-the-best-data-store.md)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-118">For more about the general principle of polyglot persistence, see [Use the best data store for the job](../guide/design-principles/use-the-best-data-store.md).</span></span> 

> [!NOTE]
> <span data-ttu-id="2b6b6-119">服務共用相同的實體資料庫伺服器並無大礙。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-119">It's fine for services to share the same physical database server.</span></span> <span data-ttu-id="2b6b6-120">當服務共用相同的結構描述、或讀取和寫入至同一組資料庫資料表時才會發生問題。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-120">The problem occurs when services share the same schema, or read and write to the same set of database tables.</span></span>


## <a name="challenges"></a><span data-ttu-id="2b6b6-121">挑戰</span><span class="sxs-lookup"><span data-stu-id="2b6b6-121">Challenges</span></span>

<span data-ttu-id="2b6b6-122">這種分散管理資料的方法會引發一些挑戰。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-122">Some challenges arise from this distributed approach to managing data.</span></span> <span data-ttu-id="2b6b6-123">首先，資料存放區之間可能會有冗餘，以致同一個資料項目出現在多個位置。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-123">First, there may be redundancy across the data stores, with the same item of data appearing in multiple places.</span></span> <span data-ttu-id="2b6b6-124">例如，資料可能會儲存作為交易的一部分，然後又儲存在其他地方以進行分析、報告或封存。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-124">For example, data might be stored as part of a transaction, then stored elsewhere for analytics, reporting, or archiving.</span></span> <span data-ttu-id="2b6b6-125">重複或分割的資料可能會導致資料完整性和一致性的問題發生。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-125">Duplicated or partitioned data can lead to issues of data integrity and consistency.</span></span> <span data-ttu-id="2b6b6-126">當資料關聯性跨越多個服務時，您就無法使用傳統的資料管理技術來強制執行關聯性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-126">When data relationships span multiple services, you can't use traditional data management techniques to enforce the relationships.</span></span>

<span data-ttu-id="2b6b6-127">傳統的資料模型化方法會使用「一地一事實」的規則。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-127">Traditional data modeling uses the rule of "one fact in one place."</span></span> <span data-ttu-id="2b6b6-128">每個實體就只會在結構描述中出現一次。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-128">Every entity appears exactly once in the schema.</span></span> <span data-ttu-id="2b6b6-129">其他實體可保有對該實體的參考，但不能加以複製。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-129">Other entities may hold references to it but not duplicate it.</span></span> <span data-ttu-id="2b6b6-130">傳統方法的明顯優勢是更新只會在一地進行，因此可避免發生資料一致性問題。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-130">The obvious advantage to the traditional approach is that updates are made in a single place, which avoids problems with data consistency.</span></span> <span data-ttu-id="2b6b6-131">在微服務架構中，您必須考慮要如何將更新傳播到各個服務，以及要如何在資料出現於多地而沒有強式一致性時管理最終一致性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-131">In a microservices architecture, you have to consider how updates are propagated across services, and how to manage eventual consistency when data appears in multiple places without strong consistency.</span></span> 

## <a name="approaches-to-managing-data"></a><span data-ttu-id="2b6b6-132">管理資料的方法</span><span class="sxs-lookup"><span data-stu-id="2b6b6-132">Approaches to managing data</span></span>

<span data-ttu-id="2b6b6-133">沒有任何一個方法可以一體適用所有情況，但在微服務架構中管理資料時有一些通用的指導方針。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-133">There is no single approach that's correct in all cases, but here are some general guidelines for managing data in a microservices architecture.</span></span>

- <span data-ttu-id="2b6b6-134">可能的話，請採用最終一致性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-134">Embrace eventual consistency where possible.</span></span> <span data-ttu-id="2b6b6-135">了解系統的哪些地方需要強式一致性或 ACID 交易，哪些地方則可接受最終一致性。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-135">Understand the places in the system where you need strong consistency or ACID transactions, and the places where eventual consistency is acceptable.</span></span>

- <span data-ttu-id="2b6b6-136">當您需要強式一致性保證時，某項服務可能代表給定實體的真實來源，並透過 API 公開。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-136">When you need strong consistency guarantees, one service may represent the source of truth for a given entity, which is exposed through an API.</span></span> <span data-ttu-id="2b6b6-137">其他服務則可自己保有該資料或資料子集的複本，並最終與主要資料保持一致，但不會考慮真實來源。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-137">Other services might hold their own copy of the data, or a subset of the data, that is eventually consistent with the master data but not considered the source of truth.</span></span> <span data-ttu-id="2b6b6-138">例如，讓我們設想有一個電子商務系統具有客戶訂單服務和建議服務。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-138">For example, imagine an e-commerce system with a customer order service and a recommendation service.</span></span> <span data-ttu-id="2b6b6-139">建議服務可能會接聽訂單服務的事件，但如果客戶要求退款，則具有完整交易記錄的是訂單服務，而非建議服務。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-139">The recommendation service might listen to events from the order service, but if a customer requests a refund, it is the order service, not the recommendation service, that has the complete transaction history.</span></span>

- <span data-ttu-id="2b6b6-140">針對交易，請使用[排程器代理程式監督員](../patterns/scheduler-agent-supervisor.md)和[補償交易](../patterns/compensating-transaction.md)等模式來確保數個服務之間的資料能保持一致。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-140">For transactions, use patterns such as [Scheduler Agent Supervisor](../patterns/scheduler-agent-supervisor.md) and [Compensating Transaction](../patterns/compensating-transaction.md) to keep data consistent across several services.</span></span>  <span data-ttu-id="2b6b6-141">您可能需要另外儲存一塊資料來擷取跨越多個服務的工作單位狀態，以免多個服務之間發生局部失敗。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-141">You may need to store an additional piece of data that captures the state of a unit of work that spans multiple services, to avoid partial failure among multiple services.</span></span> <span data-ttu-id="2b6b6-142">例如，在多步驟交易進行時，於長期佇列上保留工作項目。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-142">For example, keep a work item on a durable queue while a multi-step transaction is in progress.</span></span> 

- <span data-ttu-id="2b6b6-143">僅儲存服務所需的資料。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-143">Store only the data that a service needs.</span></span> <span data-ttu-id="2b6b6-144">服務可能只需要領域實體的一部分相關資訊。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-144">A service might only need a subset of information about a domain entity.</span></span> <span data-ttu-id="2b6b6-145">例如，在「出貨」限界內容中，我們需要知道哪些客戶與特定的遞送有關聯。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-145">For example, in the Shipping bounded context, we need to know which customer is associated to a particular delivery.</span></span> <span data-ttu-id="2b6b6-146">但我們不需要客戶的帳單地址 (地址是由「帳戶」限界內容負責管理)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-146">But we don't need the customer's billing address &mdash; that's managed by the Accounts bounded context.</span></span> <span data-ttu-id="2b6b6-147">在這裡，仔細思考領域並使用 DDD 方法會有所幫助。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-147">Thinking carefully about the domain, and using a DDD approach, can help here.</span></span> 

- <span data-ttu-id="2b6b6-148">請想想您的服務是否一致且鬆散結合。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-148">Consider whether your services are coherent and loosely coupled.</span></span> <span data-ttu-id="2b6b6-149">如果有兩個服務會持續彼此交換資訊，而導致頻繁通訊的 API，您可能需要合併這兩個服務或重構其功能，以便重繪服務的界限。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-149">If two services are continually exchanging information with each other, resulting in chatty APIs, you may need to redraw your service boundaries, by merging two services or refactoring their functionality.</span></span>

- <span data-ttu-id="2b6b6-150">請使用[事件驅動架構樣式](../guide/architecture-styles/event-driven.md)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-150">Use an [event driven architecture style](../guide/architecture-styles/event-driven.md).</span></span> <span data-ttu-id="2b6b6-151">在此架構樣式中，服務會在其公用模型或實體有所變更時發佈事件。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-151">In this architecture style, a service publishes an event when there are changes to its public models or entities.</span></span> <span data-ttu-id="2b6b6-152">有相關的服務可以訂閱這些事件。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-152">Interested services can subscribe to these events.</span></span> <span data-ttu-id="2b6b6-153">例如，另一個服務可以使用這些事件來建構資料的具體化檢視，這會更適合查詢使用。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-153">For example, another service could use the events to construct a materialized view of the data that is more suitable for querying.</span></span> 

- <span data-ttu-id="2b6b6-154">擁有事件的服務應該要發佈結構描述，以供用來將事件自動序列化和還原序列化，避免發行者和訂閱者緊密結合。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-154">A service that owns events should publish a schema that can be used to automate serializing and deserializing the events, to avoid tight coupling between publishers and subscribers.</span></span> <span data-ttu-id="2b6b6-155">您可以考慮使用 JSON 結構描述或是 [Microsoft Bond](https://github.com/Microsoft/bond)、Protobuf、Avro 之類的架構。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-155">Consider JSON schema or a framework like [Microsoft Bond](https://github.com/Microsoft/bond), Protobuf, or Avro.</span></span>  
 
- <span data-ttu-id="2b6b6-156">若規模很大，事件可能會成為系統的瓶頸，因此請考慮使用彙總或批次處理，以降低總負載。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-156">At high scale, events can become a bottleneck on the system, so consider using aggregation or batching to reduce the total load.</span></span> 

## <a name="drone-delivery-choosing-the-data-stores"></a><span data-ttu-id="2b6b6-157">無人機遞送：選擇資料存放區</span><span class="sxs-lookup"><span data-stu-id="2b6b6-157">Drone Delivery: Choosing the data stores</span></span> 

<span data-ttu-id="2b6b6-158">雖然只有幾項服務，但出貨限界內容還是能說明本節所討論的幾項要點。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-158">Even with only a few services, the Shipping bounded context illustrates several of the points discussed in this section.</span></span> 

<span data-ttu-id="2b6b6-159">當使用者在安排新的遞送時，用戶端要求中會包含有關遞送的資訊 (例如，取貨和卸貨位置) 以及有關包裹的資訊 (例如，大小和重量)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-159">When a user schedules a new delivery, the client request includes information about the both the delivery, such as the pickup and dropoff locations, and about the package, such as the size and weight.</span></span> <span data-ttu-id="2b6b6-160">這些資訊會定義工作單位，並由「擷取」服務傳送至事件中樞。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-160">This information defines a unit of work, which the Ingestion service sends to Event Hubs.</span></span> <span data-ttu-id="2b6b6-161">當排程器服務在執行工作流程時，工作單位必須留在永續性儲存體中，以免有任何遞送要求遺失。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-161">It's important that the unit of work stays in persistent storage while the Scheduler service is executing the workflow, so that no delivery requests are lost.</span></span> <span data-ttu-id="2b6b6-162">如需更多有關工作流程的討論，請參閱[擷取與工作流程](./ingestion-workflow.md)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-162">For more discussion of the workflow, see [Ingestion and workflow](./ingestion-workflow.md).</span></span> 

<span data-ttu-id="2b6b6-163">不同的後端服務會關心不同部分的要求資訊，並且也會具有不同的讀取和寫入設定檔。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-163">The various backend services care about different portions of the information in the request, and also have different read and write profiles.</span></span> 

### <a name="delivery-service"></a><span data-ttu-id="2b6b6-164">遞送服務</span><span class="sxs-lookup"><span data-stu-id="2b6b6-164">Delivery service</span></span>

<span data-ttu-id="2b6b6-165">遞送服務會儲存目前排定或進行中之遞送的相關資訊。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-165">The Delivery service stores information about every delivery that is currently scheduled or in progress.</span></span> <span data-ttu-id="2b6b6-166">它會接聽無人機的事件，並追蹤進行中遞送的狀態。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-166">It listens for events from the drones, and tracks the status of deliveries that are in progress.</span></span> <span data-ttu-id="2b6b6-167">它也會透過遞送狀態更新傳送領域事件。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-167">It also sends domain events with delivery status updates.</span></span>

<span data-ttu-id="2b6b6-168">使用者應該會在等待包裹時頻繁地檢查遞送狀態。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-168">It's expected that users will frequently check the status of a delivery while they are waiting for their package.</span></span> <span data-ttu-id="2b6b6-169">因此，遞送服務所需的資料存放區必須著重在長期儲存體的輸送量 (讀取和寫入)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-169">Therefore, the Delivery service requires a data store that emphasizes throughput (read and write) over long-term storage.</span></span> <span data-ttu-id="2b6b6-170">此外，遞送服務不會執行任何複雜的查詢或分析，其只會擷取給定遞送的最新狀態。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-170">Also, the Delivery service does not perform any complex queries or analysis, it simply fetches the latest status for a given delivery.</span></span> <span data-ttu-id="2b6b6-171">遞送服務小組選擇使用 Azure Redis 快取，因為它具有優秀的讀寫效能。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-171">The Delivery service team chose Azure Redis Cache for its high read-write performance.</span></span> <span data-ttu-id="2b6b6-172">儲存於 Redis 的資訊存留時間會較短。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-172">The information stored in Redis is relatively short-lived.</span></span> <span data-ttu-id="2b6b6-173">遞送完成後，「遞送記錄」服務即為記錄系統。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-173">Once a delivery is complete, the Delivery History service is the system of record.</span></span>

### <a name="delivery-history-service"></a><span data-ttu-id="2b6b6-174">遞送記錄服務</span><span class="sxs-lookup"><span data-stu-id="2b6b6-174">Delivery History service</span></span>

<span data-ttu-id="2b6b6-175">遞送記錄服務會接聽遞送服務的遞送狀態事件。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-175">The Delivery History service listens for delivery status events from the Delivery service.</span></span> <span data-ttu-id="2b6b6-176">其會將此資料儲存於長期儲存體中。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-176">It stores this data in long-term storage.</span></span> <span data-ttu-id="2b6b6-177">此記錄資料有兩個不同的使用案例，其各有不同的資料儲存體需求。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-177">There are two different use-cases for this historical data, which have different data storage requirements.</span></span> 

<span data-ttu-id="2b6b6-178">第一個案例是為了進行資料分析而彙總資料，以便進行業務最佳化或改善服務品質。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-178">The first scenario is aggregating the data for the purpose of data analytics, in order to optimize the business or improve the quality of the service.</span></span> <span data-ttu-id="2b6b6-179">請注意，遞送記錄服務不會實際地對資料執行分析。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-179">Note that the Delivery History service doesn't perform the actual analysis of the data.</span></span> <span data-ttu-id="2b6b6-180">它只負責擷取和儲存。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-180">It's only responsible for the ingestion and storage.</span></span> <span data-ttu-id="2b6b6-181">在此案例中，儲存體必須進行最佳化以便能針對大型資料集進行資料分析，使用「讀取時建立結構描述」方法來因應各種資料來源。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-181">For this scenario, the storage must be optimized for data analysis over a large set of data, using a schema-on-read approach to accommodate a variety of data sources.</span></span> <span data-ttu-id="2b6b6-182">此案例很適合使用 [Azure Data Lake Store](/azure/data-lake-store/)。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-182">[Azure Data Lake Store](/azure/data-lake-store/) is a good fit for this scenario.</span></span> <span data-ttu-id="2b6b6-183">Data Lake Store 是與 Hadoop Distributed File System (HDFS) 相容的 Apache Hadoop 檔案系統，並已針對資料分析案例的效能做過調整。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-183">Data Lake Store is an Apache Hadoop file system compatible with Hadoop Distributed File System (HDFS), and is tuned for performance for data analytics scenarios.</span></span> 

<span data-ttu-id="2b6b6-184">另一個案例則可讓使用者在遞送完成後，查詢遞送的記錄。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-184">The other scenario is enabling users to look up the history of a delivery after the delivery is completed.</span></span> <span data-ttu-id="2b6b6-185">Azure Data Lake 並未特別針對此案例進行最佳化。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-185">Azure Data Lake is not particularly optimized for this scenario.</span></span> <span data-ttu-id="2b6b6-186">為了達到最佳效能，Microsoft 建議您將時間序列資料儲存在 Data Lake 中依日期區分的資料夾內。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-186">For optimal performance, Microsoft recommends storing time-series data in Data Lake in folders partitioned by date.</span></span> <span data-ttu-id="2b6b6-187">(請參閱[針對效能目的調整 Azure Data Lake Store](/azure/data-lake-store/data-lake-store-performance-tuning-guidance))。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-187">(See [Tuning Azure Data Lake Store for performance](/azure/data-lake-store/data-lake-store-performance-tuning-guidance)).</span></span> <span data-ttu-id="2b6b6-188">不過，該結構不太適合用來依識別碼查閱個別記錄。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-188">However, that structure is not optimal for looking up individual records by ID.</span></span> <span data-ttu-id="2b6b6-189">除非您還知道時間戳記，否則依識別碼進行查閱時必須掃描整個集合。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-189">Unless you also know the timestamp, a lookup by ID requires scanning the entire collection.</span></span> <span data-ttu-id="2b6b6-190">因此，遞送記錄服務也會將記錄資料的一部分儲存在 Cosmos DB 中，以便您可以快速查閱。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-190">Therefore, the Delivery History service also stores a subset of the historical data in Cosmos DB for quicker lookup.</span></span> <span data-ttu-id="2b6b6-191">記錄不需要永遠留在 Cosmos DB 中。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-191">The records don't need to stay in Cosmos DB indefinitely.</span></span> <span data-ttu-id="2b6b6-192">比如說，您可以在一個月後將較舊的遞送資料封存。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-192">Older deliveries can be archived &mdash; say, after a month.</span></span> <span data-ttu-id="2b6b6-193">您可以透過偶爾執行批次程序來進行此作業。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-193">This could be done by running an occasional batch process.</span></span>

### <a name="package-service"></a><span data-ttu-id="2b6b6-194">包裹服務</span><span class="sxs-lookup"><span data-stu-id="2b6b6-194">Package service</span></span>

<span data-ttu-id="2b6b6-195">包裹服務會儲存所有包裹的相關資訊。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-195">The Package service stores information about all of the packages.</span></span> <span data-ttu-id="2b6b6-196">包裹的儲存體需求如下：</span><span class="sxs-lookup"><span data-stu-id="2b6b6-196">The storage requirements for the Package are:</span></span> 

- <span data-ttu-id="2b6b6-197">長期儲存體。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-197">Long-term storage.</span></span>
- <span data-ttu-id="2b6b6-198">能夠處理大量包裹，這需要很高的寫入輸送量。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-198">Able to handle a high volume of packages, requiring high write throughput.</span></span>
- <span data-ttu-id="2b6b6-199">支援依包裹識別碼進行簡單查詢。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-199">Support simple queries by package ID.</span></span> <span data-ttu-id="2b6b6-200">沒有複雜的參考完整性聯結或需求。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-200">No complex joins or requirements for referential integrity.</span></span>

<span data-ttu-id="2b6b6-201">因為包裹資料沒有關聯性，因此適合使用文件導向的資料庫，而 Cosmos DB 可以使用分區化集合來實現極高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-201">Because the package data is not relational, a document oriented database is appropriate, and Cosmos DB can achieve very high throughput by using sharded collections.</span></span> <span data-ttu-id="2b6b6-202">負責維護包裹服務的小組熟悉 MEAN 堆疊 (MongoDB、Express.js、AngularJS 和 Node.js)，因此他們會選取 [MongoDB API](/azure/cosmos-db/mongodb-introduction) 來用於 Cosmos DB。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-202">The team that works on the Package service is familiar with the MEAN stack (MongoDB, Express.js, AngularJS, and Node.js), so they select the [MongoDB API](/azure/cosmos-db/mongodb-introduction) for Cosmos DB.</span></span> <span data-ttu-id="2b6b6-203">這麼做可讓該小組運用其現有的 MongoDB 經驗，同時又獲得 Cosmos DB (一項受控 Azure 服務) 的好處。</span><span class="sxs-lookup"><span data-stu-id="2b6b6-203">That lets them leverage their existing experience with MongoDB, while getting the benefits of Cosmos DB, which is a managed Azure service.</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="2b6b6-204">服務間通訊</span><span class="sxs-lookup"><span data-stu-id="2b6b6-204">Interservice communication</span></span>](./interservice-communication.md)